# Enhancing Classification Accuracy using Ensemble Learning: A Case Study with SVM and Random Forest

This repository delves into the realm of ensemble learning, showcasing how we can harness the combined power of Support Vector Machines (SVM) and Random Forest classifiers to predict the occurrence of death events in the Heart Failure Clinical Records dataset. By leveraging their individual strengths, we aim to surpass the predictive accuracy achievable by either model alone.

## Project Goals:
**1. Dive Deeper into the Data:** We'll embark on a journey of exploration, unveiling patterns and hidden gems within the Heart Failure Clinical Records dataset. Statistical summaries and insightful visualizations will be our tools to decipher the characteristics of patients and the intricacies of the death event variable.

**2. Model Training Powerhouse:** We'll establish two formidable models – an SVM, renowned for its decision boundary prowess, and a Random Forest, boasting an ensemble of decision trees. Both will be meticulously trained on the carefully prepared training data, absorbing valuable knowledge about predicting death events.

**3. Prediction Fusion:** Harnessing the wisdom of both models, we'll employ a cunning strategy – taking the mode (most frequent prediction) of their individual outputs for each test sample. This fusion aims to capitalize on their complementary strengths, potentially leading to enhanced predictive accuracy.

**4. Performance Evaluation under the Microscope:** We won't leave any stone unturned when assessing our combined model's performance. A battery of metrics will be deployed, including accuracy, precision, recall, F1-score, ROC AUC, Cohen's kappa, and Matthews correlation coefficient, providing a comprehensive evaluation of its effectiveness.

**5. Visualizing the Journey:** To gain a deeper understanding of the model's decision-making process and classification trends, we'll create a confusion matrix, revealing the distribution of true and predicted labels, and an ROC curve, depicting the trade-off between true positive and false positive rates.
